{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///Users/mohammadsaalim/projects/src/lib/lm-studio.ts"],"sourcesContent":["export const CONFIG = {\n    baseUrl: process.env.LM_STUDIO_BASE_URL || \"http://127.0.0.1:1234/v1\",\n    timeoutMs: 25000,\n};\n\nexport async function detectModelCapabilities(baseUrl: string) {\n    try {\n        const res = await fetch(`${baseUrl}/models`, {\n            signal: AbortSignal.timeout(2000),\n            headers: { \"Content-Type\": \"application/json\" }\n        });\n\n        if (!res.ok) throw new Error(`Status ${res.status}`);\n\n        const data = await res.json();\n        // Prefer the first non-embedding model\n        const model = data.data?.find((m: any) => !m.id.includes(\"embedding\"));\n\n        if (!model) return null;\n\n        return {\n            id: model.id,\n            isChat: model.id.toLowerCase().includes(\"instruct\") || model.id.toLowerCase().includes(\"chat\") || model.id.toLowerCase().includes(\"gpt\"),\n        };\n    } catch (error) {\n        console.warn(\"[Capability Detection Failed]\", error);\n        return null;\n    }\n}\n\nexport async function analyzeText(text: string, targetLanguage: string = \"English\") {\n    // 1. Detect Capabilities\n    let modelId = process.env.LM_STUDIO_MODEL;\n    let endpoint = \"chat/completions\";\n\n    if (!modelId) {\n        const caps = await detectModelCapabilities(CONFIG.baseUrl);\n        if (caps) {\n            modelId = caps.id;\n        } else {\n            console.warn(\"Could not detect model, failing over to default.\");\n            modelId = \"local-model\";\n        }\n    }\n\n    // 2. Prepare Payload (Sanitized)\n    const systemPrompt = `You are noCap, a gen-z slang expert.\nYou must analyze the user's message and output the result in ${targetLanguage}.\n\nYour task:\n1. Analyze the user's message.\n2. \"sentence_meaning\": Provide a VIBE-BASED translation in ${targetLanguage}. Capture the emotion and intent.\n3. \"terms\": Identify specific slang phrases. \n   - CRITICAL: Treat multi-word slang as SINGLE units (e.g. \"Oh hell naw\").\n   - Meaning: Explain the usage/context purely in ${targetLanguage}.\n   - Example: A natural usage example (keep the slang in English, but you can translate the rest of the sentence to ${targetLanguage} if appropriate).\n4. Output STRICTLY a valid JSON object.\n\nOutput Language: ${targetLanguage}\nOutput Language: ${targetLanguage}\nOutput Language: ${targetLanguage}\n\nStructure:\n{\n  \"sentence_meaning\": \"The overall translation/vibe written in ${targetLanguage}.\",\n  \"terms\": [\n    {\n      \"term\": \"phrase or word\",\n      \"meaning\": \"definition written in ${targetLanguage}\",\n      \"example\": \"usage example\"\n    }\n  ]\n}`;\n\n    const payload = {\n        model: modelId,\n        messages: [\n            { role: \"system\", content: systemPrompt },\n            { role: \"user\", content: `${text}\\n\\nIMPORTANT: Provide all definitions and translations in ${targetLanguage}.` }\n        ],\n        temperature: 0.3, // Lower temperature for more consistent JSON\n        stream: false\n    };\n\n    console.log(`[Request] Sending to ${CONFIG.baseUrl}/${endpoint} with model ${modelId} | Language: ${targetLanguage}`);\n\n    // 3. Send Request\n    let response = await fetch(`${CONFIG.baseUrl}/${endpoint}`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify(payload),\n        signal: AbortSignal.timeout(CONFIG.timeoutMs)\n    });\n\n    // 4. Fallback for legacy endpoint\n    if (!response.ok && (response.status === 404 || response.status === 400)) {\n        console.warn(`[First Attempt Failed] ${response.status}. Retrying with legacy completion endpoint...`);\n        const legacyPayload = {\n            model: modelId,\n            prompt: `${systemPrompt}\\n\\nUser: ${text}\\n\\nIMPORTANT: Provide all definitions and translations in ${targetLanguage}.\\n\\nResponse:`,\n            temperature: 0.3,\n            max_tokens: 500\n        };\n        response = await fetch(`${CONFIG.baseUrl}/completions`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify(legacyPayload),\n            signal: AbortSignal.timeout(CONFIG.timeoutMs)\n        });\n    }\n\n    if (!response.ok) {\n        throw new Error(`LM Studio error: ${response.statusText}`);\n    }\n\n    // 5. Parse Response\n    const data = await response.json();\n    let reply = \"\";\n\n    if (data.choices?.[0]?.message?.content) {\n        reply = data.choices[0].message.content;\n    } else if (data.choices?.[0]?.text) {\n        reply = data.choices[0].text;\n    } else {\n        reply = \"No response generated.\";\n    }\n\n    return reply;\n}\n"],"names":[],"mappings":";;;;;;;;AAAO,MAAM,SAAS;IAClB,SAAS,QAAQ,GAAG,CAAC,kBAAkB,IAAI;IAC3C,WAAW;AACf;AAEO,eAAe,wBAAwB,OAAe;IACzD,IAAI;QACA,MAAM,MAAM,MAAM,MAAM,GAAG,QAAQ,OAAO,CAAC,EAAE;YACzC,QAAQ,YAAY,OAAO,CAAC;YAC5B,SAAS;gBAAE,gBAAgB;YAAmB;QAClD;QAEA,IAAI,CAAC,IAAI,EAAE,EAAE,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,IAAI,MAAM,EAAE;QAEnD,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,uCAAuC;QACvC,MAAM,QAAQ,KAAK,IAAI,EAAE,KAAK,CAAC,IAAW,CAAC,EAAE,EAAE,CAAC,QAAQ,CAAC;QAEzD,IAAI,CAAC,OAAO,OAAO;QAEnB,OAAO;YACH,IAAI,MAAM,EAAE;YACZ,QAAQ,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,eAAe,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,WAAW,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC;QACtI;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,IAAI,CAAC,iCAAiC;QAC9C,OAAO;IACX;AACJ;AAEO,eAAe,YAAY,IAAY,EAAE,iBAAyB,SAAS;IAC9E,yBAAyB;IACzB,IAAI,UAAU,QAAQ,GAAG,CAAC,eAAe;IACzC,IAAI,WAAW;IAEf,IAAI,CAAC,SAAS;QACV,MAAM,OAAO,MAAM,wBAAwB,OAAO,OAAO;QACzD,IAAI,MAAM;YACN,UAAU,KAAK,EAAE;QACrB,OAAO;YACH,QAAQ,IAAI,CAAC;YACb,UAAU;QACd;IACJ;IAEA,iCAAiC;IACjC,MAAM,eAAe,CAAC;6DACmC,EAAE,eAAe;;;;2DAInB,EAAE,eAAe;;;kDAG1B,EAAE,eAAe;oHACiD,EAAE,eAAe;;;iBAGpH,EAAE,eAAe;iBACjB,EAAE,eAAe;iBACjB,EAAE,eAAe;;;;+DAI6B,EAAE,eAAe;;;;wCAIxC,EAAE,eAAe;;;;CAIxD,CAAC;IAEE,MAAM,UAAU;QACZ,OAAO;QACP,UAAU;YACN;gBAAE,MAAM;gBAAU,SAAS;YAAa;YACxC;gBAAE,MAAM;gBAAQ,SAAS,GAAG,KAAK,2DAA2D,EAAE,eAAe,CAAC,CAAC;YAAC;SACnH;QACD,aAAa;QACb,QAAQ;IACZ;IAEA,QAAQ,GAAG,CAAC,CAAC,qBAAqB,EAAE,OAAO,OAAO,CAAC,CAAC,EAAE,SAAS,YAAY,EAAE,QAAQ,aAAa,EAAE,gBAAgB;IAEpH,kBAAkB;IAClB,IAAI,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,CAAC,EAAE,UAAU,EAAE;QACxD,QAAQ;QACR,SAAS;YAAE,gBAAgB;QAAmB;QAC9C,MAAM,KAAK,SAAS,CAAC;QACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;IAChD;IAEA,kCAAkC;IAClC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,MAAM,KAAK,OAAO,SAAS,MAAM,KAAK,GAAG,GAAG;QACtE,QAAQ,IAAI,CAAC,CAAC,uBAAuB,EAAE,SAAS,MAAM,CAAC,6CAA6C,CAAC;QACrG,MAAM,gBAAgB;YAClB,OAAO;YACP,QAAQ,GAAG,aAAa,UAAU,EAAE,KAAK,2DAA2D,EAAE,eAAe,cAAc,CAAC;YACpI,aAAa;YACb,YAAY;QAChB;QACA,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,YAAY,CAAC,EAAE;YACpD,QAAQ;YACR,SAAS;gBAAE,gBAAgB;YAAmB;YAC9C,MAAM,KAAK,SAAS,CAAC;YACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;QAChD;IACJ;IAEA,IAAI,CAAC,SAAS,EAAE,EAAE;QACd,MAAM,IAAI,MAAM,CAAC,iBAAiB,EAAE,SAAS,UAAU,EAAE;IAC7D;IAEA,oBAAoB;IACpB,MAAM,OAAO,MAAM,SAAS,IAAI;IAChC,IAAI,QAAQ;IAEZ,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAS;QACrC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;IAC3C,OAAO,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,MAAM;QAChC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,IAAI;IAChC,OAAO;QACH,QAAQ;IACZ;IAEA,OAAO;AACX"}},
    {"offset": {"line": 183, "column": 0}, "map": {"version":3,"sources":["file:///Users/mohammadsaalim/projects/src/app/api/chat/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { analyzeText } from '@/lib/lm-studio';\n\nexport async function POST(req: Request) {\n    try {\n        const body = await req.json();\n        const userMessage = body.message?.trim();\n        const language = body.language || \"English\";\n\n        if (!userMessage) {\n            return NextResponse.json({ error: \"Message cannot be empty\" }, { status: 400 });\n        }\n\n        const reply = await analyzeText(userMessage, language);\n\n        return NextResponse.json({ reply });\n\n    } catch (error) {\n        console.error(\"[Server Internal Error]\", error);\n        return NextResponse.json(\n            { error: \"Internal Server Error\" },\n            { status: 500 }\n        );\n    }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEO,eAAe,KAAK,GAAY;IACnC,IAAI;QACA,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,cAAc,KAAK,OAAO,EAAE;QAClC,MAAM,WAAW,KAAK,QAAQ,IAAI;QAElC,IAAI,CAAC,aAAa;YACd,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAA0B,GAAG;gBAAE,QAAQ;YAAI;QACjF;QAEA,MAAM,QAAQ,MAAM,IAAA,2IAAW,EAAC,aAAa;QAE7C,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE;QAAM;IAErC,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,gJAAY,CAAC,IAAI,CACpB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAEtB;AACJ"}}]
}