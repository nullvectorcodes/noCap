{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///Users/mohammadsaalim/projects/src/app/api/chat/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\n\n// --- Configuration ---\nconst CONFIG = {\n    baseUrl: process.env.LM_STUDIO_BASE_URL || \"http://127.0.0.1:1234/v1\",\n    timeoutMs: 25000,\n};\n\n// --- Helpers ---\n\n/**\n * Detects the loaded model and determines the best endpoint usage.\n */\nasync function detectModelCapabilities(baseUrl: string) {\n    try {\n        const res = await fetch(`${baseUrl}/models`, {\n            signal: AbortSignal.timeout(2000),\n            headers: { \"Content-Type\": \"application/json\" }\n        });\n\n        if (!res.ok) throw new Error(`Status ${res.status}`);\n\n        const data = await res.json();\n        // Prefer the first non-embedding model\n        const model = data.data?.find((m: any) => !m.id.includes(\"embedding\"));\n\n        if (!model) return null;\n\n        return {\n            id: model.id,\n            isChat: model.id.toLowerCase().includes(\"instruct\") || model.id.toLowerCase().includes(\"chat\") || model.id.toLowerCase().includes(\"gpt\"),\n        };\n    } catch (error) {\n        console.warn(\"[Capability Detection Failed]\", error);\n        return null;\n    }\n}\n\nexport async function POST(req: Request) {\n    try {\n        const body = await req.json();\n        const userMessage = body.message?.trim();\n\n        if (!userMessage) {\n            return NextResponse.json({ error: \"Message cannot be empty\" }, { status: 400 });\n        }\n\n        // 1. Detect Capabilities\n        let modelId = process.env.LM_STUDIO_MODEL;\n        let endpoint = \"chat/completions\";\n\n        if (!modelId) {\n            const caps = await detectModelCapabilities(CONFIG.baseUrl);\n            if (caps) {\n                modelId = caps.id;\n            } else {\n                console.warn(\"Could not detect model, failing over to default.\");\n                modelId = \"local-model\";\n            }\n        }\n\n        // 2. Prepare Payload (Sanitized)\n        // We strictly ask for JSON to support multiple terms\n        const systemPrompt = `You are noCap, a multilingual slang explainer. \nYour task:\n1. Analyze the user's message.\n2. First, provide the \"sentence_meaning\": A clear, plain English translation of the WHOLE sentence, capturing the vibe.\n3. Then, identify individual terms.\n   - If SLANG: Identify ALL slang terms, provide a clear meaning and a simple example.\n   - If STANDARD/GREETING: Treat key words as terms.\n4. Output STRICTLY a JSON object. Do not explain.\n\nStructure:\n{\n  \"sentence_meaning\": \"The overall translation of the sentence.\",\n  \"terms\": [\n    {\n      \"term\": \"term_1\",\n      \"meaning\": \"definition\",\n      \"example\": \"example sentence\"\n    }\n  ]\n}`;\n\n        const payload = {\n            model: modelId,\n            messages: [\n                { role: \"system\", content: systemPrompt },\n                { role: \"user\", content: userMessage }\n            ],\n            temperature: 0.3, // Lower temperature for more consistent JSON\n            stream: false\n        };\n\n        console.log(`[Request] Sending to ${CONFIG.baseUrl}/${endpoint} with model ${modelId}`);\n\n        // 3. Send Request\n        let response = await fetch(`${CONFIG.baseUrl}/${endpoint}`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify(payload),\n            signal: AbortSignal.timeout(CONFIG.timeoutMs)\n        });\n\n        // 4. Fallback for legacy endpoint\n        if (!response.ok && (response.status === 404 || response.status === 400)) {\n            console.warn(`[First Attempt Failed] ${response.status}. Retrying with legacy completion endpoint...`);\n            const legacyPayload = {\n                model: modelId,\n                prompt: `${systemPrompt}\\n\\nUser: ${userMessage}\\n\\nResponse:`,\n                temperature: 0.3,\n                max_tokens: 500\n            };\n            response = await fetch(`${CONFIG.baseUrl}/completions`, {\n                method: \"POST\",\n                headers: { \"Content-Type\": \"application/json\" },\n                body: JSON.stringify(legacyPayload),\n                signal: AbortSignal.timeout(CONFIG.timeoutMs)\n            });\n        }\n\n        if (!response.ok) {\n            const errorBody = await response.text();\n            console.error(`[LM Studio Fatal Error] ${response.status}: ${errorBody}`);\n            return NextResponse.json(\n                { error: \"Local AI engine rejected the request\" },\n                { status: 502 }\n            );\n        }\n\n        // 5. Parse Response\n        const data = await response.json();\n        let reply = \"\";\n\n        if (data.choices?.[0]?.message?.content) {\n            reply = data.choices[0].message.content;\n        } else if (data.choices?.[0]?.text) {\n            reply = data.choices[0].text;\n        } else {\n            reply = \"No response generated.\";\n        }\n\n        return NextResponse.json({ reply });\n\n    } catch (error) {\n        console.error(\"[Server Internal Error]\", error);\n        return NextResponse.json(\n            { error: \"Internal Server Error\" },\n            { status: 500 }\n        );\n    }\n}\n"],"names":[],"mappings":";;;;AAAA;;AAEA,wBAAwB;AACxB,MAAM,SAAS;IACX,SAAS,QAAQ,GAAG,CAAC,kBAAkB,IAAI;IAC3C,WAAW;AACf;AAEA,kBAAkB;AAElB;;CAEC,GACD,eAAe,wBAAwB,OAAe;IAClD,IAAI;QACA,MAAM,MAAM,MAAM,MAAM,GAAG,QAAQ,OAAO,CAAC,EAAE;YACzC,QAAQ,YAAY,OAAO,CAAC;YAC5B,SAAS;gBAAE,gBAAgB;YAAmB;QAClD;QAEA,IAAI,CAAC,IAAI,EAAE,EAAE,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,IAAI,MAAM,EAAE;QAEnD,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,uCAAuC;QACvC,MAAM,QAAQ,KAAK,IAAI,EAAE,KAAK,CAAC,IAAW,CAAC,EAAE,EAAE,CAAC,QAAQ,CAAC;QAEzD,IAAI,CAAC,OAAO,OAAO;QAEnB,OAAO;YACH,IAAI,MAAM,EAAE;YACZ,QAAQ,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,eAAe,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,WAAW,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC;QACtI;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,IAAI,CAAC,iCAAiC;QAC9C,OAAO;IACX;AACJ;AAEO,eAAe,KAAK,GAAY;IACnC,IAAI;QACA,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,cAAc,KAAK,OAAO,EAAE;QAElC,IAAI,CAAC,aAAa;YACd,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAA0B,GAAG;gBAAE,QAAQ;YAAI;QACjF;QAEA,yBAAyB;QACzB,IAAI,UAAU,QAAQ,GAAG,CAAC,eAAe;QACzC,IAAI,WAAW;QAEf,IAAI,CAAC,SAAS;YACV,MAAM,OAAO,MAAM,wBAAwB,OAAO,OAAO;YACzD,IAAI,MAAM;gBACN,UAAU,KAAK,EAAE;YACrB,OAAO;gBACH,QAAQ,IAAI,CAAC;gBACb,UAAU;YACd;QACJ;QAEA,iCAAiC;QACjC,qDAAqD;QACrD,MAAM,eAAe,CAAC;;;;;;;;;;;;;;;;;;;CAmB7B,CAAC;QAEM,MAAM,UAAU;YACZ,OAAO;YACP,UAAU;gBACN;oBAAE,MAAM;oBAAU,SAAS;gBAAa;gBACxC;oBAAE,MAAM;oBAAQ,SAAS;gBAAY;aACxC;YACD,aAAa;YACb,QAAQ;QACZ;QAEA,QAAQ,GAAG,CAAC,CAAC,qBAAqB,EAAE,OAAO,OAAO,CAAC,CAAC,EAAE,SAAS,YAAY,EAAE,SAAS;QAEtF,kBAAkB;QAClB,IAAI,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,CAAC,EAAE,UAAU,EAAE;YACxD,QAAQ;YACR,SAAS;gBAAE,gBAAgB;YAAmB;YAC9C,MAAM,KAAK,SAAS,CAAC;YACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;QAChD;QAEA,kCAAkC;QAClC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,MAAM,KAAK,OAAO,SAAS,MAAM,KAAK,GAAG,GAAG;YACtE,QAAQ,IAAI,CAAC,CAAC,uBAAuB,EAAE,SAAS,MAAM,CAAC,6CAA6C,CAAC;YACrG,MAAM,gBAAgB;gBAClB,OAAO;gBACP,QAAQ,GAAG,aAAa,UAAU,EAAE,YAAY,aAAa,CAAC;gBAC9D,aAAa;gBACb,YAAY;YAChB;YACA,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,YAAY,CAAC,EAAE;gBACpD,QAAQ;gBACR,SAAS;oBAAE,gBAAgB;gBAAmB;gBAC9C,MAAM,KAAK,SAAS,CAAC;gBACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;YAChD;QACJ;QAEA,IAAI,CAAC,SAAS,EAAE,EAAE;YACd,MAAM,YAAY,MAAM,SAAS,IAAI;YACrC,QAAQ,KAAK,CAAC,CAAC,wBAAwB,EAAE,SAAS,MAAM,CAAC,EAAE,EAAE,WAAW;YACxE,OAAO,gJAAY,CAAC,IAAI,CACpB;gBAAE,OAAO;YAAuC,GAChD;gBAAE,QAAQ;YAAI;QAEtB;QAEA,oBAAoB;QACpB,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,IAAI,QAAQ;QAEZ,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAS;YACrC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;QAC3C,OAAO,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,MAAM;YAChC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,IAAI;QAChC,OAAO;YACH,QAAQ;QACZ;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE;QAAM;IAErC,EAAE,OAAO,OAAO;QACZ,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,gJAAY,CAAC,IAAI,CACpB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAEtB;AACJ"}}]
}