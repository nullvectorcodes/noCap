{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 106, "column": 0}, "map": {"version":3,"sources":["file:///Users/mohammadsaalim/projects/src/lib/lm-studio.ts"],"sourcesContent":["export const CONFIG = {\n    baseUrl: process.env.LM_STUDIO_BASE_URL || \"http://127.0.0.1:1234/v1\",\n    timeoutMs: 25000,\n};\n\nexport async function detectModelCapabilities(baseUrl: string) {\n    try {\n        const res = await fetch(`${baseUrl}/models`, {\n            signal: AbortSignal.timeout(2000),\n            headers: { \"Content-Type\": \"application/json\" }\n        });\n\n        if (!res.ok) throw new Error(`Status ${res.status}`);\n\n        const data = await res.json();\n        // Prefer the first non-embedding model\n        const model = data.data?.find((m: any) => !m.id.includes(\"embedding\"));\n\n        if (!model) return null;\n\n        return {\n            id: model.id,\n            isChat: model.id.toLowerCase().includes(\"instruct\") || model.id.toLowerCase().includes(\"chat\") || model.id.toLowerCase().includes(\"gpt\"),\n        };\n    } catch (error) {\n        console.warn(\"[Capability Detection Failed]\", error);\n        return null;\n    }\n}\n\nexport async function analyzeText(text: string) {\n    // 1. Detect Capabilities\n    let modelId = process.env.LM_STUDIO_MODEL;\n    let endpoint = \"chat/completions\";\n\n    if (!modelId) {\n        const caps = await detectModelCapabilities(CONFIG.baseUrl);\n        if (caps) {\n            modelId = caps.id;\n        } else {\n            console.warn(\"Could not detect model, failing over to default.\");\n            modelId = \"local-model\";\n        }\n    }\n\n    // 2. Prepare Payload (Sanitized)\n    const systemPrompt = `You are noCap, a gen-z slang expert.\nYour task:\n1. Analyze the user's message.\n2. \"sentence_meaning\": Provide a VIBE-BASED translation. Capture the emotion and intent (e.g. \"I'm shocked!\" instead of literal words).\n3. \"terms\": Identify specific slang phrases. \n   - CRITICAL: Treat multi-word slang as SINGLE units (e.g. \"Oh hell naw\", \"dead ass\", \"for real\"). Do NOT split them.\n   - If a phrase like \"Oh hell naw\" is used, list it as ONE term.\n   - Meaning: Explain the usage/context (e.g. \"Used to express strong disbelief\").\n   - Example: A natural usage example.\n4. Output STRICTLY a JSON object.\n\nStructure:\n{\n  \"sentence_meaning\": \"The overall translation/vibe.\",\n  \"terms\": [\n    {\n      \"term\": \"phrase or word\",\n      \"meaning\": \"contextual definition\",\n      \"example\": \"usage example\"\n    }\n  ]\n}`;\n\n    const payload = {\n        model: modelId,\n        messages: [\n            { role: \"system\", content: systemPrompt },\n            { role: \"user\", content: text }\n        ],\n        temperature: 0.3, // Lower temperature for more consistent JSON\n        stream: false\n    };\n\n    console.log(`[Request] Sending to ${CONFIG.baseUrl}/${endpoint} with model ${modelId}`);\n\n    // 3. Send Request\n    let response = await fetch(`${CONFIG.baseUrl}/${endpoint}`, {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify(payload),\n        signal: AbortSignal.timeout(CONFIG.timeoutMs)\n    });\n\n    // 4. Fallback for legacy endpoint\n    if (!response.ok && (response.status === 404 || response.status === 400)) {\n        console.warn(`[First Attempt Failed] ${response.status}. Retrying with legacy completion endpoint...`);\n        const legacyPayload = {\n            model: modelId,\n            prompt: `${systemPrompt}\\n\\nUser: ${text}\\n\\nResponse:`,\n            temperature: 0.3,\n            max_tokens: 500\n        };\n        response = await fetch(`${CONFIG.baseUrl}/completions`, {\n            method: \"POST\",\n            headers: { \"Content-Type\": \"application/json\" },\n            body: JSON.stringify(legacyPayload),\n            signal: AbortSignal.timeout(CONFIG.timeoutMs)\n        });\n    }\n\n    if (!response.ok) {\n        throw new Error(`LM Studio error: ${response.statusText}`);\n    }\n\n    // 5. Parse Response\n    const data = await response.json();\n    let reply = \"\";\n\n    if (data.choices?.[0]?.message?.content) {\n        reply = data.choices[0].message.content;\n    } else if (data.choices?.[0]?.text) {\n        reply = data.choices[0].text;\n    } else {\n        reply = \"No response generated.\";\n    }\n\n    return reply;\n}\n"],"names":[],"mappings":";;;;;;;;AAAO,MAAM,SAAS;IAClB,SAAS,QAAQ,GAAG,CAAC,kBAAkB,IAAI;IAC3C,WAAW;AACf;AAEO,eAAe,wBAAwB,OAAe;IACzD,IAAI;QACA,MAAM,MAAM,MAAM,MAAM,GAAG,QAAQ,OAAO,CAAC,EAAE;YACzC,QAAQ,YAAY,OAAO,CAAC;YAC5B,SAAS;gBAAE,gBAAgB;YAAmB;QAClD;QAEA,IAAI,CAAC,IAAI,EAAE,EAAE,MAAM,IAAI,MAAM,CAAC,OAAO,EAAE,IAAI,MAAM,EAAE;QAEnD,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,uCAAuC;QACvC,MAAM,QAAQ,KAAK,IAAI,EAAE,KAAK,CAAC,IAAW,CAAC,EAAE,EAAE,CAAC,QAAQ,CAAC;QAEzD,IAAI,CAAC,OAAO,OAAO;QAEnB,OAAO;YACH,IAAI,MAAM,EAAE;YACZ,QAAQ,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,eAAe,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC,WAAW,MAAM,EAAE,CAAC,WAAW,GAAG,QAAQ,CAAC;QACtI;IACJ,EAAE,OAAO,OAAO;QACZ,QAAQ,IAAI,CAAC,iCAAiC;QAC9C,OAAO;IACX;AACJ;AAEO,eAAe,YAAY,IAAY;IAC1C,yBAAyB;IACzB,IAAI,UAAU,QAAQ,GAAG,CAAC,eAAe;IACzC,IAAI,WAAW;IAEf,IAAI,CAAC,SAAS;QACV,MAAM,OAAO,MAAM,wBAAwB,OAAO,OAAO;QACzD,IAAI,MAAM;YACN,UAAU,KAAK,EAAE;QACrB,OAAO;YACH,QAAQ,IAAI,CAAC;YACb,UAAU;QACd;IACJ;IAEA,iCAAiC;IACjC,MAAM,eAAe,CAAC;;;;;;;;;;;;;;;;;;;;;CAqBzB,CAAC;IAEE,MAAM,UAAU;QACZ,OAAO;QACP,UAAU;YACN;gBAAE,MAAM;gBAAU,SAAS;YAAa;YACxC;gBAAE,MAAM;gBAAQ,SAAS;YAAK;SACjC;QACD,aAAa;QACb,QAAQ;IACZ;IAEA,QAAQ,GAAG,CAAC,CAAC,qBAAqB,EAAE,OAAO,OAAO,CAAC,CAAC,EAAE,SAAS,YAAY,EAAE,SAAS;IAEtF,kBAAkB;IAClB,IAAI,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,CAAC,EAAE,UAAU,EAAE;QACxD,QAAQ;QACR,SAAS;YAAE,gBAAgB;QAAmB;QAC9C,MAAM,KAAK,SAAS,CAAC;QACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;IAChD;IAEA,kCAAkC;IAClC,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,SAAS,MAAM,KAAK,OAAO,SAAS,MAAM,KAAK,GAAG,GAAG;QACtE,QAAQ,IAAI,CAAC,CAAC,uBAAuB,EAAE,SAAS,MAAM,CAAC,6CAA6C,CAAC;QACrG,MAAM,gBAAgB;YAClB,OAAO;YACP,QAAQ,GAAG,aAAa,UAAU,EAAE,KAAK,aAAa,CAAC;YACvD,aAAa;YACb,YAAY;QAChB;QACA,WAAW,MAAM,MAAM,GAAG,OAAO,OAAO,CAAC,YAAY,CAAC,EAAE;YACpD,QAAQ;YACR,SAAS;gBAAE,gBAAgB;YAAmB;YAC9C,MAAM,KAAK,SAAS,CAAC;YACrB,QAAQ,YAAY,OAAO,CAAC,OAAO,SAAS;QAChD;IACJ;IAEA,IAAI,CAAC,SAAS,EAAE,EAAE;QACd,MAAM,IAAI,MAAM,CAAC,iBAAiB,EAAE,SAAS,UAAU,EAAE;IAC7D;IAEA,oBAAoB;IACpB,MAAM,OAAO,MAAM,SAAS,IAAI;IAChC,IAAI,QAAQ;IAEZ,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAS;QACrC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;IAC3C,OAAO,IAAI,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,MAAM;QAChC,QAAQ,KAAK,OAAO,CAAC,EAAE,CAAC,IAAI;IAChC,OAAO;QACH,QAAQ;IACZ;IAEA,OAAO;AACX"}},
    {"offset": {"line": 238, "column": 0}, "map": {"version":3,"sources":["file:///Users/mohammadsaalim/projects/src/app/api/analyze-image/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { createWorker } from 'tesseract.js';\nimport { analyzeText } from '@/lib/lm-studio';\nimport path from 'path';\n\nexport async function POST(req: Request) {\n    try {\n        const formData = await req.formData();\n        const file = formData.get('image') as File | null;\n\n        if (!file) {\n            return NextResponse.json({ error: \"No image file provided\" }, { status: 400 });\n        }\n\n        // Convert File to Buffer\n        const arrayBuffer = await file.arrayBuffer();\n        const buffer = Buffer.from(arrayBuffer);\n\n        // Perform OCR - Optimized for speed & Local Execution\n        // Explicitly defining path to local node_modules prevents Bun/Next.js from failing to find the worker\n        // or trying to load it from a CDN (which is slow/broken).\n        const workerPath = path.join(process.cwd(), 'node_modules', 'tesseract.js', 'src', 'worker-script', 'node', 'index.js');\n        const corePath = path.join(process.cwd(), 'node_modules', 'tesseract.js-core', 'tesseract-core.wasm.js');\n\n        console.log(`[OCR] Initializing worker...`);\n\n        // Race condition timeout - if worker creation hangs, kill it.\n        const workerPromise = (async () => {\n            const worker = await createWorker('eng', 1, {\n                workerPath,\n                corePath,\n                logger: m => {\n                    if (m.status === 'recognizing text') console.log(`[OCR] Progress: ${(m.progress * 100).toFixed(0)}%`);\n                },\n                // Disable auto-downloading if possible, but 'eng' usually triggers a check.\n                // We ensure 'workerPath' and 'corePath' are local to avoid remote Code execution.\n                cachePath: path.join(process.cwd(), '.tess-cache'), // Cache trained data locally\n            });\n\n            // 2. Set parameters for speed (LSTM only, Assume single uniform block)\n            await worker.setParameters({\n                tessedit_pageseg_mode: '6' as any, // PSM_SINGLE_BLOCK\n                tessedit_ocr_engine_mode: '2' as any, // OEM_LSTM_ONLY\n                tessjs_create_pdf: '0',\n                tessjs_create_hocr: '0',\n                tessjs_create_tsv: '0',\n                tessjs_create_box: '0',\n                tessjs_create_unlv: '0',\n                tessjs_create_osd: '0',\n            });\n\n            const ret = await worker.recognize(buffer);\n            const extractedText = ret.data.text.trim();\n            await worker.terminate();\n            return extractedText;\n        })();\n\n        // Hard timeout of 10 seconds for OCR\n        const timeoutPromise = new Promise<string>((_, reject) => {\n            setTimeout(() => reject(new Error(\"OCR Timed Out\")), 10000);\n        });\n\n        const extractedText = await Promise.race([workerPromise, timeoutPromise]);\n\n        if (!extractedText) {\n            return NextResponse.json({ error: \"No text found in image\" }, { status: 400 });\n        }\n\n        // --- Aggressive Cleaning & Human Phrase Extraction ---\n        // 1. Split into lines\n        const lines = extractedText.split('\\n');\n\n        // 2. Filter & Normalize\n        const humanPhrases: string[] = [];\n        const ignoredPatterns = [\n            /^\\d{1,2}:\\d{2}/,       // Timestamps like 12:45\n            /^\\d{1,2}\\s*[ap]m/i,    // 12 PM\n            /^(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)/i, // Dates\n            /^(sunday|monday|tuesday|wednesday|thursday|friday|saturday)/i, // Days\n            /^(youtube|instagram|tiktok|snapchat|twitter|x|facebook)/i, // Platforms\n            /^\\d+(\\.\\d+)?[kmbt]?\\s*(views|likes|comments|shares)/i, // Metrics\n            /^reply/i,              // UI actions\n            /^translate/i,\n            /^original/i,\n        ];\n\n        for (const line of lines) {\n            let processed = line.trim();\n            if (!processed) continue;\n\n            // Remove noise chars\n            processed = processed.replace(/[â€¢|>>]/g, '').trim();\n\n            // Skip if it matches ignored patterns\n            if (ignoredPatterns.some(p => p.test(processed))) continue;\n\n            // Prioritize short, conversational lines (likely slang)\n            // Skip long paragraphs unless they look very slang-heavy\n            if (processed.length > 2) {\n                humanPhrases.push(processed);\n            }\n        }\n\n        const cleanedText = humanPhrases.join(' ');\n        const normalizeForCheck = cleanedText.toLowerCase();\n\n        // --- Early Exit Logic ---\n        // Expanded fuzzy list of common slang to check before calling AI\n        // We match against the normalized \"human\" text\n        const COMMON_SLANG = [\n            /\\b(cap|bet|fr|mid|rizz|sus|finna|yeet|simp|drip|cheugy|bussin|sheesh|vibe|gyat|skibidi|fanum|tax|sigma|chug|mog|mew|looksmax|goon|edg|aura|cooked|ate|serve)\\b/i,\n            /\\b(no\\s*cap|for\\s*real|on\\s*god|dead\\s*ass|slay\\s*queen|main\\s*character|canon\\s*event|hell\\s*naw+|down\\s*bad)\\b/i\n        ];\n\n        const hasPotentialSlang = COMMON_SLANG.some(regex => regex.test(normalizeForCheck));\n\n        if (!hasPotentialSlang) {\n            console.log(\"[Early Exit] No slang detected in text:\", normalizeForCheck);\n            return NextResponse.json({\n                extractedText: cleanedText || extractedText, // Use cleaned if available\n                reply: JSON.stringify({\n                    sentence_meaning: \"No slang detected. This looks like: \\\"\" + (cleanedText || \"Unintelligible text\") + \"\\\"\",\n                    terms: []\n                })\n            });\n        }\n\n        // --- Text Reduction ---\n        // Use the cleaned text for AI analysis\n        const limitedText = cleanedText.length > 300\n            ? cleanedText.substring(0, 300) + \"...\"\n            : cleanedText;\n\n        // Analyze with AI\n        const reply = await analyzeText(limitedText);\n\n        return NextResponse.json({\n            extractedText: cleanedText, // Return full text for UI\n            reply\n        });\n\n    } catch (error: any) {\n        console.error(\"[Image Analysis Error]\", error);\n\n        const errorMessage = error.message === \"OCR Timed Out\"\n            ? \"Image processing took too long. Please try a clearer or smaller image.\"\n            : \"Failed to process image (Server Error)\";\n\n        return NextResponse.json(\n            { error: errorMessage },\n            { status: 500 }\n        );\n    }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAEO,eAAe,KAAK,GAAY;IACnC,IAAI;QACA,MAAM,WAAW,MAAM,IAAI,QAAQ;QACnC,MAAM,OAAO,SAAS,GAAG,CAAC;QAE1B,IAAI,CAAC,MAAM;YACP,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAyB,GAAG;gBAAE,QAAQ;YAAI;QAChF;QAEA,yBAAyB;QACzB,MAAM,cAAc,MAAM,KAAK,WAAW;QAC1C,MAAM,SAAS,OAAO,IAAI,CAAC;QAE3B,sDAAsD;QACtD,sGAAsG;QACtG,0DAA0D;QAC1D,MAAM,aAAa,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,gBAAgB,gBAAgB,OAAO,iBAAiB,QAAQ;QAC5G,MAAM,WAAW,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,gBAAgB,qBAAqB;QAE/E,QAAQ,GAAG,CAAC,CAAC,4BAA4B,CAAC;QAE1C,8DAA8D;QAC9D,MAAM,gBAAgB,CAAC;YACnB,MAAM,SAAS,MAAM,IAAA,iKAAY,EAAC,OAAO,GAAG;gBACxC;gBACA;gBACA,QAAQ,CAAA;oBACJ,IAAI,EAAE,MAAM,KAAK,oBAAoB,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,CAAC,EAAE,QAAQ,GAAG,GAAG,EAAE,OAAO,CAAC,GAAG,CAAC,CAAC;gBACxG;gBACA,4EAA4E;gBAC5E,kFAAkF;gBAClF,WAAW,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;YACxC;YAEA,uEAAuE;YACvE,MAAM,OAAO,aAAa,CAAC;gBACvB,uBAAuB;gBACvB,0BAA0B;gBAC1B,mBAAmB;gBACnB,oBAAoB;gBACpB,mBAAmB;gBACnB,mBAAmB;gBACnB,oBAAoB;gBACpB,mBAAmB;YACvB;YAEA,MAAM,MAAM,MAAM,OAAO,SAAS,CAAC;YACnC,MAAM,gBAAgB,IAAI,IAAI,CAAC,IAAI,CAAC,IAAI;YACxC,MAAM,OAAO,SAAS;YACtB,OAAO;QACX,CAAC;QAED,qCAAqC;QACrC,MAAM,iBAAiB,IAAI,QAAgB,CAAC,GAAG;YAC3C,WAAW,IAAM,OAAO,IAAI,MAAM,mBAAmB;QACzD;QAEA,MAAM,gBAAgB,MAAM,QAAQ,IAAI,CAAC;YAAC;YAAe;SAAe;QAExE,IAAI,CAAC,eAAe;YAChB,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAyB,GAAG;gBAAE,QAAQ;YAAI;QAChF;QAEA,wDAAwD;QACxD,sBAAsB;QACtB,MAAM,QAAQ,cAAc,KAAK,CAAC;QAElC,wBAAwB;QACxB,MAAM,eAAyB,EAAE;QACjC,MAAM,kBAAkB;YACpB;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;SACH;QAED,KAAK,MAAM,QAAQ,MAAO;YACtB,IAAI,YAAY,KAAK,IAAI;YACzB,IAAI,CAAC,WAAW;YAEhB,qBAAqB;YACrB,YAAY,UAAU,OAAO,CAAC,WAAW,IAAI,IAAI;YAEjD,sCAAsC;YACtC,IAAI,gBAAgB,IAAI,CAAC,CAAA,IAAK,EAAE,IAAI,CAAC,aAAa;YAElD,wDAAwD;YACxD,yDAAyD;YACzD,IAAI,UAAU,MAAM,GAAG,GAAG;gBACtB,aAAa,IAAI,CAAC;YACtB;QACJ;QAEA,MAAM,cAAc,aAAa,IAAI,CAAC;QACtC,MAAM,oBAAoB,YAAY,WAAW;QAEjD,2BAA2B;QAC3B,iEAAiE;QACjE,+CAA+C;QAC/C,MAAM,eAAe;YACjB;YACA;SACH;QAED,MAAM,oBAAoB,aAAa,IAAI,CAAC,CAAA,QAAS,MAAM,IAAI,CAAC;QAEhE,IAAI,CAAC,mBAAmB;YACpB,QAAQ,GAAG,CAAC,2CAA2C;YACvD,OAAO,gJAAY,CAAC,IAAI,CAAC;gBACrB,eAAe,eAAe;gBAC9B,OAAO,KAAK,SAAS,CAAC;oBAClB,kBAAkB,2CAA2C,CAAC,eAAe,qBAAqB,IAAI;oBACtG,OAAO,EAAE;gBACb;YACJ;QACJ;QAEA,yBAAyB;QACzB,uCAAuC;QACvC,MAAM,cAAc,YAAY,MAAM,GAAG,MACnC,YAAY,SAAS,CAAC,GAAG,OAAO,QAChC;QAEN,kBAAkB;QAClB,MAAM,QAAQ,MAAM,IAAA,2IAAW,EAAC;QAEhC,OAAO,gJAAY,CAAC,IAAI,CAAC;YACrB,eAAe;YACf;QACJ;IAEJ,EAAE,OAAO,OAAY;QACjB,QAAQ,KAAK,CAAC,0BAA0B;QAExC,MAAM,eAAe,MAAM,OAAO,KAAK,kBACjC,2EACA;QAEN,OAAO,gJAAY,CAAC,IAAI,CACpB;YAAE,OAAO;QAAa,GACtB;YAAE,QAAQ;QAAI;IAEtB;AACJ"}}]
}